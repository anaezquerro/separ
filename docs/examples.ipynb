{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Examples of use**\n",
    "\n",
    "This notebook includes examples to use, deploy and even expand the [trasepar](https://github.com/anaezquerro/trasepar) repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data loading**\n",
    "\n",
    "The [data](../trasepar/data/) module contains four main classes to load [CoNLL](https://universaldependencies.org/format.html), [Enhanced CoNLL](https://universaldependencies.org/v2/conll-u.html) and [SDP](https://alt.qcri.org/semeval2015/task18/) and [PTB](https://catalog.ldc.upenn.edu/desc/addenda/LDC99T42.mrg.txt) formats. All of them share the `from_file()` method to load instances from a formatted file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ana/miniconda3/envs/separ/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from separ.data import CoNLL, EnhancedCoNLL, SDP, PTB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dependency Parsing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is an example of a sentence in the [CoNLL](https://universaldependencies.org/format.html) format ([sample.conllu](sample.conllu)):\n",
    "\n",
    "```\n",
    "# newdoc id = weblog-blogspot.com_zentelligence_20040423000200_ENG_20040423_000200\n",
    "# sent_id = weblog-blogspot.com_zentelligence_20040423000200_ENG_20040423_000200-0001\n",
    "# newpar id = weblog-blogspot.com_zentelligence_20040423000200_ENG_20040423_000200-p0001\n",
    "# text = What if Google Morphed Into GoogleOS?\n",
    "1\tWhat\twhat\tPRON\tWP\tPronType=Int\t0\troot\t0:root\t_\n",
    "2\tif\tif\tSCONJ\tIN\t_\t4\tmark\t4:mark\t_\n",
    "3\tGoogle\tGoogle\tPROPN\tNNP\tNumber=Sing\t4\tnsubj\t4:nsubj\t_\n",
    "4\tMorphed\tmorph\tVERB\tVBD\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\t1\tadvcl\t1:advcl:if\t_\n",
    "5\tInto\tinto\tADP\tIN\t_\t6\tcase\t6:case\t_\n",
    "6\tGoogleOS\tGoogleOS\tPROPN\tNNP\tNumber=Sing\t4\tobl\t4:obl:into\tSpaceAfter=No\n",
    "7\t?\t?\tPUNCT\t.\t_\t4\tpunct\t4:punct\t_\n",
    "```\n",
    "\n",
    "The `CoNLL` class is used to load a complete CoNLL document and extract the _dependency graphs_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CoNLL file has (1) sentences\n",
      "# newdoc id = weblog-blogspot.com_zentelligence_20040423000200_ENG_20040423_000200\n",
      "# sent_id = weblog-blogspot.com_zentelligence_20040423000200_ENG_20040423_000200-0001\n",
      "# newpar id = weblog-blogspot.com_zentelligence_20040423000200_ENG_20040423_000200-p0001\n",
      "# text = What if Google Morphed Into GoogleOS?\n",
      "1\tWhat\twhat\tPRON\tWP\tPronType=Int\t0\troot\t0:root\t_\n",
      "2\tif\tif\tSCONJ\tIN\t_\t4\tmark\t4:mark\t_\n",
      "3\tGoogle\tGoogle\tPROPN\tNNP\tNumber=Sing\t4\tnsubj\t4:nsubj\t_\n",
      "4\tMorphed\tmorph\tVERB\tVBD\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\t1\tadvcl\t1:advcl:if\t_\n",
      "5\tInto\tinto\tADP\tIN\t_\t6\tcase\t6:case\t_\n",
      "6\tGoogleOS\tGoogleOS\tPROPN\tNNP\tNumber=Sing\t4\tobl\t4:obl:into\tSpaceAfter=No\n",
      "7\t?\t?\tPUNCT\t.\t_\t4\tpunct\t4:punct\t_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "data = CoNLL.from_file('sample.conllu')\n",
    "print(f'The CoNLL file has ({len(data)}) sentences')\n",
    "print(data[0].format()) # index as a list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CoNLL.Graph` instance stores two key elements: (1) the list of nodes of the graph and (2) the list of arcs. Each element of the list of nodes is a `CoNLL.Node` object and each element of the list of arcs is an `Arc` object. The `CoNLL.Node` stores the information at word level. The `Arc` instances store the position of the head, the position of the parent and the dependency relation associated to the arc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 --(root)--> 1, 4 --(mark)--> 2, 4 --(nsubj)--> 3, 1 --(advcl)--> 4, 6 --(case)--> 5, 4 --(obl)--> 6, 4 --(punct)--> 7]\n",
      "0 1 root\n"
     ]
    }
   ],
   "source": [
    "graph = data[0]\n",
    "print(graph.arcs)\n",
    "\n",
    "# take the first arc \n",
    "arc = graph.arcs[0]\n",
    "print(arc.HEAD, arc.DEP, arc.REL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Semantic Parsing**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To load semantic graphs our code supports two different formats: [Enhanced CoNLL](https://universaldependencies.org/v2/conll-u.html) and [SDP](https://alt.qcri.org/semeval2015/task18/). The previous example ([sample.conllu](sample.conllu)) is also a valid for the [Enhanced CoNLL](https://universaldependencies.org/v2/conll-u.html) format. This is an example of an SDP sentence ([sample.sdp](sample.sdp)).\n",
    " \n",
    "```\n",
    "#SDP 2015\n",
    "#22100001\n",
    "1\tConsumers\tconsumer\tNNS\t-\t-\tn_of:x-i\t_\tARG1\tARG1\t_\t_\t_\t_\t_\t_\n",
    "2\tmay\tmay\tMD\t+\t+\tv_modal:e-h\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
    "3\twant\twant\tVB\t-\t+\tv:e-i-h\tARG1\t_\t_\t_\t_\t_\t_\t_\t_\n",
    "4\tto\tto\tTO\t-\t-\t_\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
    "5\tmove\tmove\tVB\t-\t+\tv_cause:e-i-p\t_\t_\t_\t_\t_\tsubord\t_\t_\t_\n",
    "6\ttheir\ttheir\tPRP$\t-\t+\tq:i-h-h\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
    "7\ttelephones\ttelephone\tNNS\t-\t-\tn:x\t_\t_\tARG2\tposs\t_\t_\t_\t_\t_\n",
    "8\ta\ta+little\tDT\t-\t-\tx:e-u\t_\t_\t_\t_\tmwe\t_\t_\t_\t_\n",
    "9\tlittle\ta+little\tRB\t-\t+\tx:e-u\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
    "10\tcloser\tcloser\tRBR\t-\t+\ta_to:e-i-i\t_\tARG2\t_\t_\tARG1\t_\tARG1\t_\t_\n",
    "11\tto\tto\tTO\t-\t+\tp:e-u-i\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
    "12\tthe\tthe\tDT\t-\t+\tq:i-h-h\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
    "13\tTV\ttv\tNN\t-\t+\tn:x\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
    "14\tset\tset\tNN\t-\t-\tn_of:x\t_\t_\t_\t_\t_\t_\tARG2\tBV\tcompound\n",
    "15\t.\t_\t.\t-\t-\t_\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
    "```\n",
    "\n",
    "For this type of data, we implemented the `SDP` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SDP file has (1) sentences\n",
      "#22100001\n",
      "1\tConsumers\tconsumer\tNNS\t-\t-\tn_of:x-i\t_\tARG1\tARG1\t_\t_\t_\t_\t_\t_\n",
      "2\tmay\tmay\tMD\t+\t+\tv_modal:e-h\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "3\twant\twant\tVB\t-\t+\tv:e-i-h\tARG1\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "4\tto\tto\tTO\t-\t-\t_\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "5\tmove\tmove\tVB\t-\t+\tv_cause:e-i-p\t_\t_\t_\t_\t_\tsubord\t_\t_\t_\n",
      "6\ttheir\ttheir\tPRP$\t-\t+\tq:i-h-h\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "7\ttelephones\ttelephone\tNNS\t-\t-\tn:x\t_\t_\tARG2\tposs\t_\t_\t_\t_\t_\n",
      "8\ta\ta+little\tDT\t-\t-\tx:e-u\t_\t_\t_\t_\tmwe\t_\t_\t_\t_\n",
      "9\tlittle\ta+little\tRB\t-\t+\tx:e-u\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "10\tcloser\tcloser\tRBR\t-\t+\ta_to:e-i-i\t_\tARG2\t_\t_\tARG1\t_\tARG1\t_\t_\n",
      "11\tto\tto\tTO\t-\t+\tp:e-u-i\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "12\tthe\tthe\tDT\t-\t+\tq:i-h-h\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "13\tTV\ttv\tNN\t-\t+\tn:x\t_\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "14\tset\tset\tNN\t-\t-\tn_of:x\t_\t_\t_\t_\t_\t_\tARG2\tBV\tcompound\n",
      "15\t.\t_\t.\t-\t-\t_\t_\t_\t_\t_\t_\t_\t_\t_\t_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "data = SDP.from_file('sample.sdp')\n",
    "print(f'The SDP file has ({len(data)}) sentences')\n",
    "print(data[0].format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SDP.Graph` instance also stores the list of nodes and arcs of the semantic graph. Note that, in this case, the number of arcs could be greater or lower than the number of nodes (while in `CoNLL.Graph` instances, since they represent a dependency graph, the number of nodes and arcs must match). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3 --(ARG1)--> 1,\n",
       " 5 --(ARG1)--> 1,\n",
       " 0 --(TOP)--> 2,\n",
       " 2 --(ARG1)--> 3,\n",
       " 10 --(subord)--> 5,\n",
       " 5 --(ARG2)--> 7,\n",
       " 6 --(poss)--> 7,\n",
       " 9 --(mwe)--> 8,\n",
       " 3 --(ARG2)--> 10,\n",
       " 9 --(ARG1)--> 10,\n",
       " 11 --(ARG1)--> 10,\n",
       " 11 --(ARG2)--> 14,\n",
       " 12 --(BV)--> 14,\n",
       " 13 --(compound)--> 14]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `EnhancedCoNLL` file, instead, parses the arcs from the `DEPS` column. See the following example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EnhancedCoNLL file has (1) sentences\n",
      "# newdoc id = weblog-blogspot.com_zentelligence_20040423000200_ENG_20040423_000200\n",
      "# sent_id = weblog-blogspot.com_zentelligence_20040423000200_ENG_20040423_000200-0001\n",
      "# newpar id = weblog-blogspot.com_zentelligence_20040423000200_ENG_20040423_000200-p0001\n",
      "# text = What if Google Morphed Into GoogleOS?\n",
      "1\tWhat\twhat\tPRON\tWP\tPronType=Int\t0\troot\t0:root\t_\n",
      "2\tif\tif\tSCONJ\tIN\t_\t1\tmark\t4:mark\t_\n",
      "3\tGoogle\tGoogle\tPROPN\tNNP\tNumber=Sing\t2\tnsubj\t4:nsubj\t_\n",
      "4\tMorphed\tmorph\tVERB\tVBD\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\t3\tadvcl\t1:advcl:if\t_\n",
      "5\tInto\tinto\tADP\tIN\t_\t4\tcase\t6:case\t_\n",
      "6\tGoogleOS\tGoogleOS\tPROPN\tNNP\tNumber=Sing\t5\tobl\t4:obl:into\tSpaceAfter=No\n",
      "7\t?\t?\tPUNCT\t.\t_\t6\tpunct\t4:punct\t_\n",
      "[0 --(root)--> 1, 4 --(mark)--> 2, 4 --(nsubj)--> 3, 1 --(advcl:if)--> 4, 6 --(case)--> 5, 4 --(obl:into)--> 6, 4 --(punct)--> 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "data = EnhancedCoNLL.from_file('sample.conllu')\n",
    "print(f'The EnhancedCoNLL file has ({len(data)}) sentences')\n",
    "print(data[0].format())\n",
    "print(data[0].arcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CoNLL.Graph`, `EnhancedCoNLL.Graph` and `SDP.Graph` inherit the methods from the abstract `Graph` ([trasepar/structs/graph.py](../trasepar/structs/graph.py)). We suggest looking to its Python implementation to see all their methods (extract cycles, planes, rebuild, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Constituency Parsing**\n",
    "\n",
    "The `PTB` class loads a bracketing-formatted file as the one provided in [sample.ptb](sample.ptb):\n",
    "\n",
    "```\n",
    "(S (INTJ (RB No)) (, ,) (NP-SBJ (PRP it)) (VP (VBD was) (RB n't) (NP-PRD (NNP Black) (NNP Monday))) (. .))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (INTJ (RB No)) (, ,) (NP-SBJ (PRP it)) (VP (VBD was) (RB n't) (NP-PRD (NNP Black) (NNP Monday))) (. .))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "data = PTB.from_file('sample.ptb')\n",
    "print(data[0].format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the other formats, each element of the `PTB` file is a `PTB.Tree`. Our code implements several methods to process and operate with the different elements of the tree (e.g. collapse unary chains, get the spans that conform the tree, obtain the PoS-tags, etc.). For more information, see the source code ([trasepar/data/ptb.py](../trasepar/data/ptb.py))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Linearization algorithms**\n",
    "\n",
    "The [trasepar/models](../trasepar/models) module contains the implementation of the different sequence-labeling parsers: \n",
    "\n",
    "\n",
    "| Dependency Parsing | Description | Arguments |\n",
    "|:---|:---|:---|\n",
    "| [`IndexDependencyParser`](../trasepar/models/dep/idx/parser.py) | Absolute and relative indexing | `rel` |\n",
    "| [`PoSDependencyParser`](../trasepar/models/dep/pos/parser.py) | PoS-tag relative indexing | |\n",
    "| [`BracketDependencyParser`](../trasepar/models/dep/bracket/parser.py) | $k$-planar bracket encoding | `k` | \n",
    "| [`Bit4DependencyParser`](../trasepar/models/dep/bit4/parser.py) | $1$-planar bit-encoding |  | \n",
    "| [`Bit7DependencyParser`](../trasepar/models/dep/bit7/parser.py) | $2$-planar bit-encoding |  | \n",
    "\n",
    "\n",
    "| Semantic Parsing | Description | Arguments |\n",
    "|:---|:---|:---|\n",
    "| [`IndexSemanticParser`](../trasepar/models/sdp/idx/parser.py) | Absolute and relative graph indexing | `rel` |\n",
    "| [`BracketSemanticParser`](../trasepar/models/sdp/bracket/parser.py) | $k$-planar bracket graph encoding | `k` | \n",
    "| [`Bit4SemanticParser`](../trasepar/models/sdp/bit4k/parser.py) | $4k$-bit graph encoding ($k$-planar) | `k` |\n",
    "| [`Bit6SemanticParser`](../trasepar/models/sdp/bit6k/parser.py) | $6k$-bit graph encoding ($k$-planar) | `k` |\n",
    "\n",
    "| Constituency Parsing | Description | Arguments |\n",
    "|:---|:---|:---|\n",
    "| [`IndexSemanticParser`](../trasepar/models/con/idx/parser.py) | Absolute and relative indexing | `rel` |\n",
    "\n",
    "In all parsers, the linearization process is performed with the `Labeler` inner class. The two key methods to transform an input graph or tree into a sequence of labels is performed with the `.encode()` function, while the reverse process is performed with the `decode()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dependency Parsing as Sequence Labeling**\n",
    "\n",
    "The dependency labelers work with dependency graphs (`CoNLL.Graph`). See in the source code of each class the algorithm to transform the input graph into a sequence of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arcs of the input graph: [0 --(root)--> 1, 4 --(mark)--> 2, 4 --(nsubj)--> 3, 1 --(advcl)--> 4, 6 --(case)--> 5, 4 --(obl)--> 6, 4 --(punct)--> 7]\n",
      "Sequence of labels: ['0', '4', '4', '1', '6', '4', '4']\n",
      "Dependency relations: ['root', 'mark', 'nsubj', 'advcl', 'case', 'obl', 'punct']\n",
      "Applying decoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0 --(root)--> 1,\n",
       " 4 --(mark)--> 2,\n",
       " 4 --(nsubj)--> 3,\n",
       " 1 --(advcl)--> 4,\n",
       " 6 --(case)--> 5,\n",
       " 4 --(obl)--> 6,\n",
       " 4 --(punct)--> 7]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from separ.models import IndexDependencyParser, PoSDependencyParser, BracketDependencyParser, Bit4DependencyParser, Bit7DependencyParser\n",
    "\n",
    "graph = CoNLL.from_file('sample.conllu')[0]\n",
    "idx = IndexDependencyParser.Labeler()\n",
    "print(f'Arcs of the input graph:', graph.arcs)\n",
    "labels, rels = idx.encode(graph)\n",
    "print(f'Sequence of labels:', labels)\n",
    "print(f'Dependency relations:', rels)\n",
    "print('Applying decoding...')\n",
    "idx.decode(labels, rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arcs of the input graph: [0 --(root)--> 1, 4 --(mark)--> 2, 4 --(nsubj)--> 3, 1 --(advcl)--> 4, 6 --(case)--> 5, 4 --(obl)--> 6, 4 --(punct)--> 7]\n",
      "Sequence of labels: ['/>', '<', '<', '\\\\\\\\//>', '<', '\\\\>', '>']\n",
      "Dependency relations: ['root', 'mark', 'nsubj', 'advcl', 'case', 'obl', 'punct']\n",
      "Applying decoding...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0 --(root)--> 1,\n",
       " 4 --(mark)--> 2,\n",
       " 4 --(nsubj)--> 3,\n",
       " 1 --(advcl)--> 4,\n",
       " 6 --(case)--> 5,\n",
       " 4 --(obl)--> 6,\n",
       " 4 --(punct)--> 7]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bracket = BracketDependencyParser.Labeler()\n",
    "print(f'Arcs of the input graph:', graph.arcs)\n",
    "labels, rels = bracket.encode(graph)\n",
    "print(f'Sequence of labels:', labels)\n",
    "print(f'Dependency relations:', rels)\n",
    "print('Applying decoding...')\n",
    "bracket.decode(labels, rels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Semantic Parsing as Sequence Labeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly, the semantic labelers take as input a semantic graph. The encoding process in this case only involves the _unlabeled arcs_ of the graph, meaning that they would only represent the positions of head and dependant nodes associated to each arc. See in the following example that only the _unlabeled versions_ of each arc are recovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 --(ARG1)--> 1, 5 --(ARG1)--> 1, 0 --(TOP)--> 2, 2 --(ARG1)--> 3, 10 --(subord)--> 5, 5 --(ARG2)--> 7, 6 --(poss)--> 7, 9 --(mwe)--> 8, 3 --(ARG2)--> 10, 9 --(ARG1)--> 10, 11 --(ARG1)--> 10, 11 --(ARG2)--> 14, 12 --(BV)--> 14, 13 --(compound)--> 14]\n",
      "Labels: ['3$5', '0', '2', '', '10', '', '5$6', '9', '', '3$9$11', '', '', '', '11$12$13', '']\n",
      "Applying decoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3 --(None)--> 1,\n",
       " 5 --(None)--> 1,\n",
       " 0 --(None)--> 2,\n",
       " 2 --(None)--> 3,\n",
       " 10 --(None)--> 5,\n",
       " 5 --(None)--> 7,\n",
       " 6 --(None)--> 7,\n",
       " 9 --(None)--> 8,\n",
       " 3 --(None)--> 10,\n",
       " 9 --(None)--> 10,\n",
       " 11 --(None)--> 10,\n",
       " 11 --(None)--> 14,\n",
       " 12 --(None)--> 14,\n",
       " 13 --(None)--> 14]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from separ.models import IndexSemanticParser, BracketSemanticParser, Bit4kSemanticParser, Bit6kSemanticParser\n",
    "\n",
    "graph = SDP.from_file('sample.sdp')[0]\n",
    "print(graph.arcs)\n",
    "idx = IndexSemanticParser.Labeler()\n",
    "labels = idx.encode(graph)\n",
    "print('Labels:', labels)\n",
    "print('Applying decoding...')\n",
    "idx.decode(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to also encode the information of the dependency types, the semantic labeler has the method `complete_encode()` and `complete_decode()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['3$5', '0', '2', '', '10', '', '5$6', '9', '', '3$9$11', '', '', '', '11$12$13', '']\n",
      "Applying full decoding...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3 --(ARG1)--> 1,\n",
       " 5 --(ARG1)--> 1,\n",
       " 0 --(TOP)--> 2,\n",
       " 2 --(ARG1)--> 3,\n",
       " 10 --(subord)--> 5,\n",
       " 5 --(ARG2)--> 7,\n",
       " 6 --(poss)--> 7,\n",
       " 9 --(mwe)--> 8,\n",
       " 3 --(ARG2)--> 10,\n",
       " 9 --(ARG1)--> 10,\n",
       " 11 --(ARG1)--> 10,\n",
       " 11 --(ARG2)--> 14,\n",
       " 12 --(BV)--> 14,\n",
       " 13 --(compound)--> 14]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, rels = idx.complete_encode(graph)\n",
    "print('Labels:', labels)\n",
    "print('Applying full decoding...')\n",
    "idx.complete_decode(labels, rels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Constituency Parsing as Sequence Labeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, only the indexing encoding algorithm has been implemented for constituency parsing (more on-going). As the previous explained labelers, the constituency linearization algorithms encode an input `PTB.Tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (INTJ (RB No)) (, ,) (NP-SBJ (PRP it)) (VP (VBD was) (RB n't) (NP-PRD (NNP Black) (NNP Monday))) (. .))\n",
      "['1', '1', '1', '2', '2', '3', '1', '0']\n",
      "['S', 'S', 'S', 'VP', 'VP', 'NP-PRD', 'S', '']\n",
      "['INTJ', '', 'NP-SBJ', '', '', '', '', '']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from separ.models import IndexConstituencyParser\n",
    "tree = PTB.from_file('sample.ptb')[0]\n",
    "print(tree.format())\n",
    "idx = IndexConstituencyParser.Labeler()\n",
    "labels, cons, leaves = idx.encode(tree)\n",
    "print(labels)\n",
    "print(cons)\n",
    "print(leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoding process in this case does not return arcs, but the list of spans that conform the decoded tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Span(LEFT=5, RIGHT=7, LABEL=NP-PRD),\n",
       " Span(LEFT=3, RIGHT=7, LABEL=VP),\n",
       " Span(LEFT=0, RIGHT=8, LABEL=S),\n",
       " Span(LEFT=0, RIGHT=1, LABEL=INTJ),\n",
       " Span(LEFT=2, RIGHT=3, LABEL=NP-SBJ)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = idx.decode(labels, cons, leaves)\n",
    "spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the sequence of spans, the `PTB.Tree` class uses a method to build the tree instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(S (INTJ (RB No)) (, ,) (NP-SBJ (PRP it)) (VP (VBD was) (RB n't) (NP-PRD (NNP Black) (NNP Monday))) (. .))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PTB.Tree.from_spans(tree.preterminals, spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(S (INTJ (RB No)) (, ,) (NP-SBJ (PRP it)) (VP (VBD was) (RB n't) (NP-PRD (NNP Black) (NNP Monday))) (. .))\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.format()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trasepar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
