[enc_conf]

[word_conf]
pretrained = xlm-roberta-large
finetune = True 

[train_conf]
batch_size = 100
lr = 1e-5
epochs = 100
train_patience = 20
dev_patience = 20